# Fly.io Configuration - Orbis Backend
app = "orbis-backend"  # MUDE para nome único!

primary_region = "gru"  # São Paulo

[build]
  dockerfile = "Dockerfile.railway"

[env]
  ENVIRONMENT = "production"
  PORT = "8000"
  API_HOST = "0.0.0.0"
  DEBUG = "false"
  
  # ML Models
  ASR_MODEL = "openai/whisper-base"
  ASR_DEVICE = "cpu"
  MT_MODEL = "facebook/nllb-200-distilled-600M"
  MT_DEVICE = "cpu"
  TTS_DEVICE = "cpu"
  
  # Features
  TARGET_LATENCY_MS = "800"
  MAX_ROOM_PARTICIPANTS = "50"
  ML_LAZY_LOAD = "true"
  ML_AUTO_UNLOAD_ENABLED = "true"

[http_service]
  internal_port = 8000
  force_https = true
  auto_stop_machines = false  # Sempre ativo
  auto_start_machines = true
  min_machines_running = 1
  
  [http_service.concurrency]
    type = "requests"
    soft_limit = 200
    hard_limit = 250

[[services]]
  protocol = "tcp"
  internal_port = 8000
  processes = ["app"]

  [[services.ports]]
    port = 80
    handlers = ["http"]
    force_https = true

  [[services.ports]]
    port = 443
    handlers = ["tls", "http"]
  
  [services.concurrency]
    type = "connections"
    hard_limit = 250
    soft_limit = 200

  [[services.tcp_checks]]
    interval = "15s"
    timeout = "2s"
    grace_period = "5s"

[[vm]]
  memory = '512mb'
  cpu_kind = 'shared'
  cpus = 1
